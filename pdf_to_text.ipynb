{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80eca486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a57ea695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API_KEY from environment or fallback to .env\n",
    "env_path = Path('.env')\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        if line.strip().startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        key, value = line.split('=', 1)\n",
    "        if key.strip() == 'API_KEY' and value.strip():\n",
    "            os.environ.setdefault('API_KEY', value.strip())\n",
    "            break\n",
    "\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "if not API_KEY:\n",
    "    raise RuntimeError('Set API_KEY in your environment or .env')\n",
    "\n",
    "# create an OpenAI client using the API key\n",
    "client = OpenAI(api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1404f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf4llm\n",
    "# md_text = pymupdf4llm.to_markdown(\"6832_SercePehlevan_2020.pdf\")\n",
    "\n",
    "# import pathlib\n",
    "# pathlib.Path(\"output.md\").write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c61c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=open(\"6832_SercePehlevan_2020.pdf\", \"rb\"),\n",
    "    purpose=\"user_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "beca6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_chatgpt(prompt):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"input_text\", \"text\": prompt },\n",
    "                    {\n",
    "                        \"type\": \"input_file\",\n",
    "                        \"file_id\": file.id,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"domain_1_q_1_1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "answer = generate_response_with_chatgpt(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e964d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt question files by domain (variants split via folder name):\n",
      "domain_1_randomization\n",
      " - 1.1: prompts/domain_1_randomization/question_1.txt\n",
      " - 1.2: prompts/domain_1_randomization/question_2.txt\n",
      " - 1.3: prompts/domain_1_randomization/question_3.txt\n",
      "domain_2_adhering\n",
      " - 2.1: prompts/domain_2_adhering/question_1.txt\n",
      " - 2.2: prompts/domain_2_adhering/question_2.txt\n",
      " - 2.3: prompts/domain_2_adhering/question_3.txt\n",
      " - 2.4: prompts/domain_2_adhering/question_4.txt\n",
      " - 2.5: prompts/domain_2_adhering/question_5.txt\n",
      " - 2.6: prompts/domain_2_adhering/question_6.txt\n",
      "domain_2_assigment\n",
      " - 2.1: prompts/domain_2_assigment/question_1.txt\n",
      " - 2.2: prompts/domain_2_assigment/question_2.txt\n",
      " - 2.3: prompts/domain_2_assigment/question_3.txt\n",
      " - 2.4: prompts/domain_2_assigment/question_4.txt\n",
      " - 2.5: prompts/domain_2_assigment/question_5.txt\n",
      " - 2.6: prompts/domain_2_assigment/question_6.txt\n",
      " - 2.7: prompts/domain_2_assigment/question_7.txt\n",
      "domain_3_missing_data\n",
      " - 3.1: prompts/domain_3_missing_data/question_1.txt\n",
      " - 3.2: prompts/domain_3_missing_data/question_2.txt\n",
      " - 3.3: prompts/domain_3_missing_data/question_3.txt\n",
      " - 3.4: prompts/domain_3_missing_data/question_4.txt\n",
      "domain_4_measurement\n",
      " - 4.1: prompts/domain_4_measurement/question_1.txt\n",
      " - 4.2: prompts/domain_4_measurement/question_2.txt\n",
      " - 4.3: prompts/domain_4_measurement/question_3.txt\n",
      " - 4.4: prompts/domain_4_measurement/question_4.txt\n",
      " - 4.5: prompts/domain_4_measurement/question_5.txt\n",
      "domain_5_reporting\n",
      " - 5.1: prompts/domain_5_reporting/question_1.txt\n",
      " - 5.2: prompts/domain_5_reporting/question_2.txt\n",
      " - 5.3: prompts/domain_5_reporting/question_3.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Map domain (variants via folder name) -> question code -> prompt question file path\n",
    "prompt_question_files = defaultdict(dict)\n",
    "pattern = re.compile(r\"^domain_?(\\d+)(?:_(.+))?$\")\n",
    "for prompt_path in Path('prompts').rglob('question_*.txt'):\n",
    "    match = pattern.match(prompt_path.parent.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    domain_id, variant = match.groups()\n",
    "\n",
    "    stem_parts = prompt_path.stem.split('_')\n",
    "    qnum = stem_parts[1] if len(stem_parts) > 1 else 'unknown'\n",
    "    question_code = f\"{domain_id}.{qnum}\"\n",
    "\n",
    "    domain_key = f\"domain_{domain_id}\" if not variant else f\"domain_{domain_id}_{variant}\"\n",
    "    prompt_question_files[domain_key][question_code] = str(prompt_path)\n",
    "\n",
    "# Sort questions for stable output\n",
    "prompt_question_files = {\n",
    "    domain: {code: path for code, path in sorted(questions.items())}\n",
    "    for domain, questions in sorted(prompt_question_files.items())\n",
    "}\n",
    "\n",
    "print('Prompt question files by domain (variants split via folder name):')\n",
    "for domain, questions in prompt_question_files.items():\n",
    "    print(domain)\n",
    "    for code, f in questions.items():\n",
    "        print(f\" - {code}: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ff5075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain_1_randomization -> 1.1\n",
      "Domain 1 – Question 1.1\n",
      "-----------------------\n",
      "\n",
      "Prompt:\n",
      "You are evaluating Risk of Bias Domain 1, Question 1.1:\n",
      "“Was the allocation sequence random?”\n",
      "\n",
      "Read the provided document.\n",
      "\n",
      "Your tasks:\n",
      "\n",
      "1. Identify whether the study used a truly random method to generate the allocation sequence.\n",
      "   Random methods include:\n",
      "     - computer-generated random numbers\n",
      "     - random number tables\n",
      "     - coin toss or dice rolling\n",
      "     - shuffled cards or envelopes\n",
      "     - minimization with a random element\n",
      "   Non-random or predictable methods include:\n",
      "     - alternation\n",
      "     - date of birth\n",
      "     - admission date\n",
      "     - medical record number\n",
      "     - clinician or investigator judgment\n",
      "     - any systematic or predictable rule\n",
      "\n",
      "2. Return one of the following:\n",
      "   Y  = Yes\n",
      "   PY = Probably Yes\n",
      "   NI = No Information\n",
      "   PN = Probably No\n",
      "   N  = No\n",
      "\n",
      "3. Provide a short justification explaining why the chosen answer is appropriate.\n",
      "\n",
      "4. Quote exact sentences or phrases from the document that support your conclusion.\n",
      "\n",
      "5. If no relevant information is available in the document, answer NI.\n",
      "\n",
      "Output format:\n",
      "\n",
      "Answer: <Y | PY | NI | PN | N>\n",
      "Justification: <2–4 sentences explaining reasoning>\n",
      "Quoted Evidence:\n",
      "\"<exact text copied from the document>\"\n",
      "\n",
      "domain_2_adhering -> 2.1\n",
      "Domain 2 – Question 2.1 (Effect of Adhering to Intervention)\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prompt:\n",
      "You are evaluating Risk of Bias Domain 2 for the “Effect of Adhering to Intervention.”\n",
      "This is Question 2.1:\n",
      "“Were there deviations from the intended intervention that arose because of the trial context?”\n",
      "\n",
      "Read the provided document.\n",
      "\n",
      "Your tasks:\n",
      "\n",
      "1. Identify whether any deviations from the intended intervention occurred because of the experimental context.\n",
      "   Deviations arise from the trial context when:\n",
      "     - they were caused by study procedures (e.g., enhanced monitoring, study visits, protocol-driven actions),\n",
      "     - they occurred because participants or carers were influenced by the knowledge that this was a research study,\n",
      "     - they would *not* have occurred in normal clinical practice.\n",
      "\n",
      "2. Examples include:\n",
      "     - patients modifying behavior due to study participation,\n",
      "     - clinicians altering treatment based on trial assignment knowledge,\n",
      "     - protocol-driven deviations intended only for the study,\n",
      "     - study-specific co-interventions.\n",
      "\n",
      "3. Deviations *not* due to the trial context include:\n",
      "     - routine clinical variations,\n",
      "     - adherence problems occurring in normal clinical environments,\n",
      "     - deviations unrelated to study processes.\n",
      "\n",
      "4. Return one of the following:\n",
      "   Y  = Yes (deviations due to trial context occurred)\n",
      "   PY = Probably Yes\n",
      "   NI = No Information\n",
      "   PN = Probably No\n",
      "   N  = No (no deviations due to trial context)\n",
      "\n",
      "5. Provide a short justification explaining why the chosen answer is appropriate.\n",
      "\n",
      "6. Quote exact sentences or phrases from the document that support your conclusion.\n",
      "\n",
      "7. If no information is provided about the nature or causes of deviations, answer NI.\n",
      "\n",
      "Output format:\n",
      "\n",
      "Answer: <Y | PY | NI | PN | N>\n",
      "Justification: <2–4 sentences explaining reasoning>\n",
      "Quoted Evidence:\n",
      "\"<exact text copied from the document>\"\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DOMAIN2_QUESTIONS' from 'rob2.questions' (/Users/anthony/personal_local/RoB/rob2/questions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m state = {}\n\u001b[32m     16\u001b[39m domain_prompts = prompt_question_files[domain_key]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m domain_module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrob2.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdomain_key\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m get_next_question = \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(domain_module, name)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(domain_module)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name.startswith(\u001b[33m'\u001b[39m\u001b[33mget_next_question_domain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m question_code = get_next_question(state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal_local/RoB/rob2/domain_2_assigment.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# RoB 2.0 – Domain 2: Effect of Assignment to Intervention\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DomainResult, NO, NO_INFO, Response, YES\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquestions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DOMAIN2_QUESTIONS\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDomain2Result\u001b[39;00m(DomainResult):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, judgement, explanation, path):\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'DOMAIN2_QUESTIONS' from 'rob2.questions' (/Users/anthony/personal_local/RoB/rob2/questions.py)"
     ]
    }
   ],
   "source": [
    "# Read PDF text, load a domain module, and walk its signalling questions\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from rob2.common import Response\n",
    "\n",
    "pdf_path = Path('studies/6832_SercePehlevan_2020.pdf')\n",
    "\n",
    "\n",
    "file = client.files.create(\n",
    "    file=open(pdf_path, \"rb\"),\n",
    "    purpose=\"user_data\",\n",
    ")\n",
    "\n",
    "for domain_key in prompt_question_files:\n",
    "    state = {}\n",
    "    domain_prompts = prompt_question_files[domain_key]\n",
    "    domain_module = importlib.import_module(f'rob2.{domain_key}')\n",
    "    get_next_question = next(\n",
    "        getattr(domain_module, name)\n",
    "        for name in dir(domain_module)\n",
    "        if name.startswith('get_next_question_domain')\n",
    "    )\n",
    "\n",
    "    question_code = get_next_question(state)\n",
    "    while question_code:\n",
    "        prompt_path = Path(domain_prompts.get(question_code, ''))\n",
    "        prompt_text = prompt_path.read_text(encoding='utf-8') if prompt_path.exists() else None\n",
    "        print(f\"{domain_key} -> {question_code}\")\n",
    "        if prompt_text:\n",
    "            print(prompt_text)\n",
    "        else:\n",
    "            print('Prompt not found for this question code.')\n",
    "\n",
    "        state[question_code] = Response.NI  # replace with real answer\n",
    "        break\n",
    "        question_code = get_next_question(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e217e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
